{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 1\n",
        "## Part1"
      ],
      "metadata": {
        "id": "g3oY2DPKV_r9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdFtrwRdV4bF",
        "outputId": "c50cf45d-4915-4959-bdfc-26dc91b648d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _wine_dataset:\n",
            "\n",
            "Wine recognition dataset\n",
            "------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 178\n",
            "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            " \t\t- Alcohol\n",
            " \t\t- Malic acid\n",
            " \t\t- Ash\n",
            "\t\t- Alcalinity of ash  \n",
            " \t\t- Magnesium\n",
            "\t\t- Total phenols\n",
            " \t\t- Flavanoids\n",
            " \t\t- Nonflavanoid phenols\n",
            " \t\t- Proanthocyanins\n",
            "\t\t- Color intensity\n",
            " \t\t- Hue\n",
            " \t\t- OD280/OD315 of diluted wines\n",
            " \t\t- Proline\n",
            "\n",
            "    - class:\n",
            "            - class_0\n",
            "            - class_1\n",
            "            - class_2\n",
            "\t\t\n",
            "    :Summary Statistics:\n",
            "    \n",
            "    ============================= ==== ===== ======= =====\n",
            "                                   Min   Max   Mean     SD\n",
            "    ============================= ==== ===== ======= =====\n",
            "    Alcohol:                      11.0  14.8    13.0   0.8\n",
            "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
            "    Ash:                          1.36  3.23    2.36  0.27\n",
            "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
            "    Magnesium:                    70.0 162.0    99.7  14.3\n",
            "    Total Phenols:                0.98  3.88    2.29  0.63\n",
            "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
            "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
            "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
            "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
            "    Hue:                          0.48  1.71    0.96  0.23\n",
            "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
            "    Proline:                       278  1680     746   315\n",
            "    ============================= ==== ===== ======= =====\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "This is a copy of UCI ML Wine recognition datasets.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
            "\n",
            "The data is the results of a chemical analysis of wines grown in the same\n",
            "region in Italy by three different cultivators. There are thirteen different\n",
            "measurements taken for different constituents found in the three types of\n",
            "wine.\n",
            "\n",
            "Original Owners: \n",
            "\n",
            "Forina, M. et al, PARVUS - \n",
            "An Extendible Package for Data Exploration, Classification and Correlation. \n",
            "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
            "Via Brigata Salerno, 16147 Genoa, Italy.\n",
            "\n",
            "Citation:\n",
            "\n",
            "Lichman, M. (2013). UCI Machine Learning Repository\n",
            "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
            "School of Information and Computer Science. \n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  Comparison of Classifiers in High Dimensional Settings, \n",
            "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Technometrics). \n",
            "\n",
            "  The data was used with many others for comparing various \n",
            "  classifiers. The classes are separable, though only RDA \n",
            "  has achieved 100% correct classification. \n",
            "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
            "  (All results using the leave-one-out technique) \n",
            "\n",
            "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
            "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Journal of Chemometrics).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "\n",
        "# Load the wine dataset\n",
        "wine_data = load_wine()\n",
        "\n",
        "# Print the description of the dataset\n",
        "print(wine_data.DESCR)\n",
        "\n",
        "# Access the features (X) and target (y) variables\n",
        "X = wine_data.data  # Features\n",
        "y = wine_data.target  # Target variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target1=y.tolist()\n",
        "my_set=set(target1)\n",
        "target_list=list(my_set)\n",
        "\n",
        "if 0 in target_list:\n",
        "    print(f\"The classes are from (0,1,2,.......C-1)\")\n",
        "else:\n",
        "    print(f\"The classes are from (1,2,3,.......C)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi1p65h6WJ3v",
        "outputId": "23dd3930-e9d6-40b1-9b8b-2f52926b357c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classes are from (0,1,2,.......C-1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 2"
      ],
      "metadata": {
        "id": "RwmRlqsQWRtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_label=[1]*len(wine_data.data)\n",
        "for i in range(len(y)):\n",
        "  if y[i]!=1:\n",
        "    transformed_label[i]=-1\n",
        "transformed_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apzr5GqAWUHx",
        "outputId": "6288a3f4-4a87-4c73-e8bf-ace699955da3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1,\n",
              " -1]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3"
      ],
      "metadata": {
        "id": "4gDmaBw4Wenw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalising the columns of A\n",
        "A=wine_data.data\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Normalize the columns of A\n",
        "min_vals = np.min(A, axis=0)  # Minimum values of each column\n",
        "max_vals = np.max(A, axis=0)  # Maximum values of each column\n",
        "\n",
        "# Min-Max normalization\n",
        "A_normalized = -1 + 2 * ((A - min_vals) / (max_vals - min_vals))\n",
        "\n",
        "print(\"Original matrix A:\")\n",
        "print(A)\n",
        "print(\"\\nNormalized matrix A:\")\n",
        "print(A_normalized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFiN3cDIWaF8",
        "outputId": "58c3bb8a-9e00-4557-a651-ee91301ea1ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original matrix A:\n",
            "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
            " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
            " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
            " ...\n",
            " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
            " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
            " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
            "\n",
            "Normalized matrix A:\n",
            "[[ 0.68421053 -0.61660079  0.14438503 ... -0.08943089  0.94139194\n",
            "   0.12268188]\n",
            " [ 0.14210526 -0.58893281 -0.1657754  ... -0.07317073  0.56043956\n",
            "   0.10128388]\n",
            " [ 0.12105263 -0.35968379  0.40106952 ... -0.10569106  0.39194139\n",
            "   0.29386591]\n",
            " ...\n",
            " [ 0.17894737  0.39920949 -0.03743316 ... -0.82113821 -0.78754579\n",
            "  -0.20542083]\n",
            " [ 0.12631579 -0.2687747   0.0802139  ... -0.80487805 -0.74358974\n",
            "  -0.19828816]\n",
            " [ 0.63157895  0.32806324  0.47593583 ... -0.78861789 -0.75824176\n",
            "  -0.59771755]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4"
      ],
      "metadata": {
        "id": "pISqS6VRWmQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "index_array=[i for i in range(len(wine_data.data))]\n",
        "for i in range(178):\n",
        "  random.shuffle(index_array)\n",
        "train_size=int(0.8*len(index_array)) # Use first 80 percent of the index for trainining examples and rest for testing examples\n",
        "train_index=index_array[:train_size]\n",
        "test_index=index_array[train_size:]\n",
        "train_data1=[A[i] for i in train_index]\n",
        "test_data1=[A[i] for i in test_index]\n",
        "train_data=np.array(train_data1)\n",
        "test_data=np.array(test_data1)\n",
        "train_label1=[transformed_label[i] for i in train_index]\n",
        "train_label=np.array(train_label1)\n",
        "test_label1=[transformed_label[i] for i in test_index]\n",
        "test_label=np.array(test_label1)\n"
      ],
      "metadata": {
        "id": "NZomcT0GWl14"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training data is\")\n",
        "print(train_data)\n",
        "print(\"Testing data is:\")\n",
        "print(test_data)\n",
        "print(\"Training labels Are\")\n",
        "print(train_label)\n",
        "print(\"Testing labels are:\")\n",
        "print(test_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhNGkNbwWxXC",
        "outputId": "4eb7dbde-1d03-42bc-db47-02e1a8016a90"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data is\n",
            "[[1.299e+01 1.670e+00 2.600e+00 ... 1.310e+00 3.500e+00 9.850e+02]\n",
            " [1.141e+01 7.400e-01 2.500e+00 ... 1.100e+00 2.310e+00 4.340e+02]\n",
            " [1.165e+01 1.670e+00 2.620e+00 ... 1.360e+00 3.210e+00 5.620e+02]\n",
            " ...\n",
            " [1.324e+01 2.590e+00 2.870e+00 ... 1.040e+00 2.930e+00 7.350e+02]\n",
            " [1.475e+01 1.730e+00 2.390e+00 ... 1.250e+00 2.730e+00 1.150e+03]\n",
            " [1.233e+01 1.100e+00 2.280e+00 ... 1.250e+00 1.670e+00 6.800e+02]]\n",
            "Testing data is:\n",
            "[[1.233e+01 9.900e-01 1.950e+00 1.480e+01 1.360e+02 1.900e+00 1.850e+00\n",
            "  3.500e-01 2.760e+00 3.400e+00 1.060e+00 2.310e+00 7.500e+02]\n",
            " [1.145e+01 2.400e+00 2.420e+00 2.000e+01 9.600e+01 2.900e+00 2.790e+00\n",
            "  3.200e-01 1.830e+00 3.250e+00 8.000e-01 3.390e+00 6.250e+02]\n",
            " [1.351e+01 1.800e+00 2.650e+00 1.900e+01 1.100e+02 2.350e+00 2.530e+00\n",
            "  2.900e-01 1.540e+00 4.200e+00 1.100e+00 2.870e+00 1.095e+03]\n",
            " [1.237e+01 9.400e-01 1.360e+00 1.060e+01 8.800e+01 1.980e+00 5.700e-01\n",
            "  2.800e-01 4.200e-01 1.950e+00 1.050e+00 1.820e+00 5.200e+02]\n",
            " [1.225e+01 1.730e+00 2.120e+00 1.900e+01 8.000e+01 1.650e+00 2.030e+00\n",
            "  3.700e-01 1.630e+00 3.400e+00 1.000e+00 3.170e+00 5.100e+02]\n",
            " [1.372e+01 1.430e+00 2.500e+00 1.670e+01 1.080e+02 3.400e+00 3.670e+00\n",
            "  1.900e-01 2.040e+00 6.800e+00 8.900e-01 2.870e+00 1.285e+03]\n",
            " [1.229e+01 1.410e+00 1.980e+00 1.600e+01 8.500e+01 2.550e+00 2.500e+00\n",
            "  2.900e-01 1.770e+00 2.900e+00 1.230e+00 2.740e+00 4.280e+02]\n",
            " [1.388e+01 5.040e+00 2.230e+00 2.000e+01 8.000e+01 9.800e-01 3.400e-01\n",
            "  4.000e-01 6.800e-01 4.900e+00 5.800e-01 1.330e+00 4.150e+02]\n",
            " [1.430e+01 1.920e+00 2.720e+00 2.000e+01 1.200e+02 2.800e+00 3.140e+00\n",
            "  3.300e-01 1.970e+00 6.200e+00 1.070e+00 2.650e+00 1.280e+03]\n",
            " [1.311e+01 1.900e+00 2.750e+00 2.550e+01 1.160e+02 2.200e+00 1.280e+00\n",
            "  2.600e-01 1.560e+00 7.100e+00 6.100e-01 1.330e+00 4.250e+02]\n",
            " [1.371e+01 5.650e+00 2.450e+00 2.050e+01 9.500e+01 1.680e+00 6.100e-01\n",
            "  5.200e-01 1.060e+00 7.700e+00 6.400e-01 1.740e+00 7.400e+02]\n",
            " [1.221e+01 1.190e+00 1.750e+00 1.680e+01 1.510e+02 1.850e+00 1.280e+00\n",
            "  1.400e-01 2.500e+00 2.850e+00 1.280e+00 3.070e+00 7.180e+02]\n",
            " [1.317e+01 2.590e+00 2.370e+00 2.000e+01 1.200e+02 1.650e+00 6.800e-01\n",
            "  5.300e-01 1.460e+00 9.300e+00 6.000e-01 1.620e+00 8.400e+02]\n",
            " [1.236e+01 3.830e+00 2.380e+00 2.100e+01 8.800e+01 2.300e+00 9.200e-01\n",
            "  5.000e-01 1.040e+00 7.650e+00 5.600e-01 1.580e+00 5.200e+02]\n",
            " [1.363e+01 1.810e+00 2.700e+00 1.720e+01 1.120e+02 2.850e+00 2.910e+00\n",
            "  3.000e-01 1.460e+00 7.300e+00 1.280e+00 2.880e+00 1.310e+03]\n",
            " [1.229e+01 3.170e+00 2.210e+00 1.800e+01 8.800e+01 2.850e+00 2.990e+00\n",
            "  4.500e-01 2.810e+00 2.300e+00 1.420e+00 2.830e+00 4.060e+02]\n",
            " [1.420e+01 1.760e+00 2.450e+00 1.520e+01 1.120e+02 3.270e+00 3.390e+00\n",
            "  3.400e-01 1.970e+00 6.750e+00 1.050e+00 2.850e+00 1.450e+03]\n",
            " [1.483e+01 1.640e+00 2.170e+00 1.400e+01 9.700e+01 2.800e+00 2.980e+00\n",
            "  2.900e-01 1.980e+00 5.200e+00 1.080e+00 2.850e+00 1.045e+03]\n",
            " [1.237e+01 1.210e+00 2.560e+00 1.810e+01 9.800e+01 2.420e+00 2.650e+00\n",
            "  3.700e-01 2.080e+00 4.600e+00 1.190e+00 2.300e+00 6.780e+02]\n",
            " [1.390e+01 1.680e+00 2.120e+00 1.600e+01 1.010e+02 3.100e+00 3.390e+00\n",
            "  2.100e-01 2.140e+00 6.100e+00 9.100e-01 3.330e+00 9.850e+02]\n",
            " [1.237e+01 1.070e+00 2.100e+00 1.850e+01 8.800e+01 3.520e+00 3.750e+00\n",
            "  2.400e-01 1.950e+00 4.500e+00 1.040e+00 2.770e+00 6.600e+02]\n",
            " [1.293e+01 2.810e+00 2.700e+00 2.100e+01 9.600e+01 1.540e+00 5.000e-01\n",
            "  5.300e-01 7.500e-01 4.600e+00 7.700e-01 2.310e+00 6.000e+02]\n",
            " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
            "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]\n",
            " [1.258e+01 1.290e+00 2.100e+00 2.000e+01 1.030e+02 1.480e+00 5.800e-01\n",
            "  5.300e-01 1.400e+00 7.600e+00 5.800e-01 1.550e+00 6.400e+02]\n",
            " [1.305e+01 1.730e+00 2.040e+00 1.240e+01 9.200e+01 2.720e+00 3.270e+00\n",
            "  1.700e-01 2.910e+00 7.200e+00 1.120e+00 2.910e+00 1.150e+03]\n",
            " [1.187e+01 4.310e+00 2.390e+00 2.100e+01 8.200e+01 2.860e+00 3.030e+00\n",
            "  2.100e-01 2.910e+00 2.800e+00 7.500e-01 3.640e+00 3.800e+02]\n",
            " [1.260e+01 2.460e+00 2.200e+00 1.850e+01 9.400e+01 1.620e+00 6.600e-01\n",
            "  6.300e-01 9.400e-01 7.100e+00 7.300e-01 1.580e+00 6.950e+02]\n",
            " [1.284e+01 2.960e+00 2.610e+00 2.400e+01 1.010e+02 2.320e+00 6.000e-01\n",
            "  5.300e-01 8.100e-01 4.920e+00 8.900e-01 2.150e+00 5.900e+02]\n",
            " [1.217e+01 1.450e+00 2.530e+00 1.900e+01 1.040e+02 1.890e+00 1.750e+00\n",
            "  4.500e-01 1.030e+00 2.950e+00 1.450e+00 2.230e+00 3.550e+02]\n",
            " [1.387e+01 1.900e+00 2.800e+00 1.940e+01 1.070e+02 2.950e+00 2.970e+00\n",
            "  3.700e-01 1.760e+00 4.500e+00 1.250e+00 3.400e+00 9.150e+02]\n",
            " [1.200e+01 3.430e+00 2.000e+00 1.900e+01 8.700e+01 2.000e+00 1.640e+00\n",
            "  3.700e-01 1.870e+00 1.280e+00 9.300e-01 3.050e+00 5.640e+02]\n",
            " [1.237e+01 1.630e+00 2.300e+00 2.450e+01 8.800e+01 2.220e+00 2.450e+00\n",
            "  4.000e-01 1.900e+00 2.120e+00 8.900e-01 2.780e+00 3.420e+02]\n",
            " [1.330e+01 1.720e+00 2.140e+00 1.700e+01 9.400e+01 2.400e+00 2.190e+00\n",
            "  2.700e-01 1.350e+00 3.950e+00 1.020e+00 2.770e+00 1.285e+03]\n",
            " [1.421e+01 4.040e+00 2.440e+00 1.890e+01 1.110e+02 2.850e+00 2.650e+00\n",
            "  3.000e-01 1.250e+00 5.240e+00 8.700e-01 3.330e+00 1.080e+03]\n",
            " [1.225e+01 4.720e+00 2.540e+00 2.100e+01 8.900e+01 1.380e+00 4.700e-01\n",
            "  5.300e-01 8.000e-01 3.850e+00 7.500e-01 1.270e+00 7.200e+02]\n",
            " [1.200e+01 1.510e+00 2.420e+00 2.200e+01 8.600e+01 1.450e+00 1.250e+00\n",
            "  5.000e-01 1.630e+00 3.600e+00 1.050e+00 2.650e+00 4.500e+02]]\n",
            "Training labels Are\n",
            "[ 1  1  1 -1 -1 -1  1 -1 -1  1  1 -1 -1 -1  1  1 -1 -1  1  1 -1 -1 -1  1\n",
            " -1  1 -1 -1 -1  1 -1  1  1  1 -1  1  1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1\n",
            " -1 -1  1  1 -1  1  1  1 -1 -1 -1  1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1\n",
            "  1 -1  1 -1 -1  1 -1  1  1 -1 -1  1 -1 -1 -1 -1  1  1  1  1 -1 -1 -1 -1\n",
            "  1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1 -1 -1  1 -1 -1  1  1 -1  1  1 -1\n",
            " -1  1  1 -1  1 -1 -1  1 -1  1  1  1 -1  1 -1 -1 -1 -1 -1 -1 -1  1]\n",
            "Testing labels are:\n",
            "[ 1  1 -1  1  1 -1  1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1  1 -1  1 -1 -1 -1\n",
            " -1  1 -1 -1  1 -1  1  1 -1 -1 -1  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5"
      ],
      "metadata": {
        "id": "jUWQMuY-W4wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_function(w,x):\n",
        "  if w.T@x>0:\n",
        "    pred=1\n",
        "  elif w.T@x<0:\n",
        "    pred=-1\n",
        "  return pred"
      ],
      "metadata": {
        "id": "rFlP-90EW4aP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6"
      ],
      "metadata": {
        "id": "lmdnMBoUW9v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model_w,data,label):\n",
        "  k=0\n",
        "  n=len(data)\n",
        "  for i in range(n):\n",
        "    val=prediction_function(w,data[i])\n",
        "    if val==label[i]:\n",
        "      k+=1\n",
        "  accur=float((k/n)*100)\n",
        "  return accur"
      ],
      "metadata": {
        "id": "LIsKWYU9XAzM"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}